{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from utils_notebook import histogram_experiment, dataframe_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"../results/all_db_all_training\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = pd.DataFrame()\n",
    "# For all folder in results_path\n",
    "for experiment_folder in os.listdir(results_path):\n",
    "    # Load the data\n",
    "    # if experiment starts with DDPM skip\n",
    "    # if not \"DDPM\" in experiment_folder:\n",
    "    #     continue\n",
    "    for dataset_folder in os.listdir(os.path.join(results_path, experiment_folder)):\n",
    "        if \"A_synthetic\" not in dataset_folder:\n",
    "            continue\n",
    "        try:\n",
    "            dataset_results = pd.read_csv(Path(results_path, experiment_folder,dataset_folder, \"model_metrics.csv\"))\n",
    "        except:\n",
    "            print(f\"Error loading {results_path}/{experiment_folder}/{dataset_folder}/model_metrics.csv\")\n",
    "            continue\n",
    "        dataset_results[\"experiment\"] = experiment_folder\n",
    "        dataset_results[\"dataset_name\"] = \"_\".join(dataset_folder.split(\"_\")[:-2])\n",
    "        dataset_results['dataset_version'] = dataset_folder.split(\"_\")[-1]\n",
    "        # dataset_results['nb_bins'] = int(re.search(r\"bins(\\d+)\", experiment_folder).group(1))\n",
    "        # dataset_results['T'] = int(re.search(r\"T(\\d+)\", experiment_folder).group(1))\n",
    "        dataset_results['dimension'] = dataset_results['dataset_name'].str.extract(r\"f(\\d+)\", expand=False).astype(int)\n",
    "        full_results_df = pd.concat([full_results_df, dataset_results])\n",
    "# result_path = \"../results/grid_search_new_db\"\n",
    "# for experiment_folder in os.listdir(\"../results/grid_search_new_db\"):\n",
    "#     # Load the data\n",
    "#     # if experiment starts with DDPM skip\n",
    "#     for dataset_folder in os.listdir(os.path.join(\"../results/grid_search_new_db\", experiment_folder)):\n",
    "#         if \"A_synthetic\" not in dataset_folder:\n",
    "#             continue\n",
    "#         try:\n",
    "#             dataset_results = pd.read_csv(Path(\"../results/grid_search_new_db\", experiment_folder,dataset_folder, \"model_metrics.csv\"))\n",
    "#         except:\n",
    "#             print(f\"Error loading {results_path}/{experiment_folder}/{dataset_folder}/model_metrics.csv\")\n",
    "#             continue\n",
    "#         dataset_results[\"experiment\"] = experiment_folder\n",
    "#         dataset_results[\"dataset_name\"] = \"_\".join(dataset_folder.split(\"_\")[:-2])\n",
    "#         dataset_results['dataset_version'] = dataset_folder.split(\"_\")[-1]\n",
    "#         # dataset_results['nb_bins'] = int(re.search(r\"bins(\\d+)\", experiment_folder).group(1))\n",
    "#         # dataset_results['T'] = int(re.search(r\"T(\\d+)\", experiment_folder).group(1))\n",
    "#         dataset_results['dimension'] = dataset_results['dataset_name'].str.extract(r\"f(\\d+)\", expand=False).astype(int)\n",
    "#         full_results_df = pd.concat([full_results_df, dataset_results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ddpm_shap(row, column_name):\n",
    "    if \"DDPM\" in row[\"experiment\"]:\n",
    "        return row[column_name]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "full_results_df['ddpm_shap_accuracy'] = full_results_df.apply(lambda row: extract_ddpm_shap(row, \"shap_explanation_accuracy\"), axis=1)\n",
    "full_results_df['ddpm_shap_ndcg'] = full_results_df.apply(lambda row: extract_ddpm_shap(row, \"shap_feature_importance_ndcg\"), axis=1)\n",
    "full_results_df['ddpm_shap_time'] = full_results_df.apply(lambda row: extract_ddpm_shap(row, \"shap_explanation_time\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = full_results_df.drop(columns=[\"Unnamed: 0\", \"model_name\", \"sampling_method\"], )\n",
    "full_results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df[\"dataset_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in full_results_df.columns:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract the sum of ratios\n",
    "def extract_sum_of_ratios(dataset_name):\n",
    "    # Use regex to extract all ratios after 'r' and before '_', split by '_'\n",
    "    ratios = re.findall(r'r([\\d\\.]+(?:_[\\d\\.]+)*)', dataset_name)\n",
    "    if ratios:\n",
    "        # Convert the extracted ratios to a list of floats\n",
    "        ratio_list = list(map(float, ratios[0].split('_')))\n",
    "        return sum(ratio_list) * 100\n",
    "    return 0  # Default value if no ratios are found\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "full_results_df['anomaly_ratio'] = full_results_df['dataset_name'].apply(extract_sum_of_ratios)\n",
    "# Recreate the dataset names with \"Synthetic {dimension}d, {ratio*100}% anomalies\"\n",
    "full_results_df['dataset_name'] = full_results_df['dimension'].apply(lambda x: f\"Synthetic {x}d\") + \", \" + (full_results_df['anomaly_ratio']).astype(int).astype(str) + \"\\\\% anomalies\"\n",
    "# Add ratio to dataset name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df['anomaly_ratio'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only row where nb_bins = 7 and T = 400\n",
    "# full_results_df = full_results_df[(full_results_df['nb_bins'] == 7) & (full_results_df['T'] == 400)]\n",
    "# full_results_df = full_results_df.drop(columns=[\"nb_bins\", \"T\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and std for each dataset with different version, but same experiment name\n",
    "temp_df = full_results_df.drop(columns=['training_method', \"dataset_version\"])\n",
    "mean_df = temp_df.groupby([\"experiment\", \"dataset_name\", \"anomaly_ratio\", \"dimension\"]).mean().reset_index()\n",
    "std_df = temp_df.groupby([\"experiment\", \"dataset_name\", \"anomaly_ratio\", \"dimension\"]).std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_results_df['experiment'].unique())\n",
    "print(full_results_df['dataset_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model name from experiment name, its the part before the first _\n",
    "mean_df['model_name'] = mean_df['experiment'].str.extract(r\"([A-Za-z0-9]+)_\")\n",
    "std_df['model_name'] = std_df['experiment'].str.extract(r\"([A-Za-z0-9]+)_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only rows where experiment contains \"0.5\"\n",
    "ddpm_mean_df = mean_df[mean_df['model_name'] == \"DDPM\"]\n",
    "ddpm_std_df = std_df[std_df['model_name'] == \"DDPM\"]\n",
    "ddpm_std_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_create_latex_table(mean_df, std_df, column_name, caption=\"\", label=\"\"):\n",
    "    # Step 1: Merge DataFrames on common columns\n",
    "    merged_df = pd.merge(mean_df, std_df, on=[\"dataset_name\", \"experiment\", \"dimension\", \"anomaly_ratio\"], suffixes=('_mean', '_std'))\n",
    "    # Step 2: Combine mean and std into a single column with \"mean(std)\" format\n",
    "    merged_df[f\"{column_name}_str\"] = merged_df.apply(\n",
    "        lambda row: f\"${row[f'{column_name}_mean']:.2f}({row[f'{column_name}_std']:.2f})$\", axis=1\n",
    "    )\n",
    "    # Step 3: Drop the separate mean and std columns if needed\n",
    "    merged_df = merged_df.drop(columns=[f\"{column_name}_mean\", f\"{column_name}_std\"])\n",
    "    # Pivot so that each model is a experiment\n",
    "    merged_df = merged_df.pivot(index=[\"dataset_name\"], columns=\"experiment\", values=f\"{column_name}_str\")\n",
    "    merged_df = merged_df.reset_index()\n",
    "    print(merged_df.columns)\n",
    "    latex_table = dataframe_to_latex(\n",
    "        merged_df,\n",
    "        column_format=\"llc\",  \n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        index=False\n",
    "    )\n",
    "    with open(\"latex_table.tex\", \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "    latex_table.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_and_create_latex_table(ddpm_mean_df, ddpm_std_df, \"aucroc\", caption=\"AUCROC for DDPM\", label=\"tab:ddpm_aucroc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_experiment(mean_df=ddpm_mean_df, std_df=ddpm_std_df, column=\"f1_score\", ylabel=\"F1 score\", title=\"F1 score for different experiments using DDPM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_experiment(mean_df=ddpm_mean_df, std_df=ddpm_std_df, column=\"aucroc\", ylabel=\"AUCROC\", title=\"AUCROC for different experiments of DDPM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only rows where experiment contains \"0.5\"\n",
    "dte_mean_df = mean_df[mean_df['model_name'] == \"DTEC\"]\n",
    "dte_std_df = std_df[std_df['model_name'] == \"DTEC\"]\n",
    "dte_std_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_experiment(mean_df=dte_mean_df, std_df=dte_std_df, column=\"f1_score\", ylabel=\"F1 score\", title=\"F1 score for different experiments of DTEC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_and_create_latex_table(dte_mean_df, dte_std_df, \"f1_score\", caption=\"F1 for DTEC\", label=\"tab:dte_aucroc_synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the training method\n",
    "def extract_training_method(experiment_name):\n",
    "    # Regex to match the format {model_name}_{training_method}_s{seed}\n",
    "    match = re.match(r'^[^_]+_([^_]+(?:_[^_]+)*)_s\\d+', experiment_name)\n",
    "    if match:\n",
    "        return match.group(1)  # Extract the training_method part\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "mean_df['training_method'] = mean_df['experiment'].apply(extract_training_method)\n",
    "std_df['training_method'] = std_df['experiment'].apply(extract_training_method)\n",
    "mean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
