{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 13:14:53.793604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-22 13:14:53.807456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-22 13:14:53.811664: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-22 13:14:53.822379: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-22 13:14:54.632945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent \n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from src.utils import get_dataset, select_model\n",
    "from hydra import initialize, compose\n",
    "from src.shap_explainer import ShapExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_explainability_robustness(model, instance, explain_func, perturbation_scale=0.01, num_perturbations=50):\n",
    "    \"\"\"\n",
    "    Evaluate the robustness of an explainability vector for a given instance and model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: torch.nn.Module\n",
    "        The PyTorch model to be evaluated.\n",
    "    - instance: torch.Tensor\n",
    "        The input instance for which the explainability vector is computed (1D tensor).\n",
    "    - explain_func: function\n",
    "        A function that takes `model` and `instance` as inputs and returns an explainability vector.\n",
    "    - perturbation_scale: float\n",
    "        The standard deviation of Gaussian noise added to the input for perturbations.\n",
    "    - num_perturbations: int\n",
    "        The number of perturbed instances to generate.\n",
    "\n",
    "    Returns:\n",
    "    - robustness_score: float\n",
    "        A score indicating the robustness of the explainability vector (lower is better).\n",
    "    \"\"\"\n",
    "    model.model.eval()  # Ensure the model is in evaluation mode\n",
    "    if not isinstance(instance, torch.Tensor):\n",
    "        instance = torch.tensor(instance, dtype=torch.float32)\n",
    "    # Compute the original explainability vector\n",
    "    original_explain_vector = torch.tensor(explain_func(instance))\n",
    "\n",
    "    # Initialize a list to store differences in explainability vectors\n",
    "    explain_diff_magnitudes = []\n",
    "\n",
    "    for _ in range(num_perturbations):\n",
    "        # Generate a perturbed instance by adding Gaussian noise\n",
    "        perturbation = torch.randn_like(instance) * perturbation_scale\n",
    "        perturbed_instance = instance + perturbation\n",
    "\n",
    "        # Compute the explainability vector for the perturbed instance\n",
    "        perturbed_explain_vector = torch.tensor(explain_func(perturbed_instance))\n",
    "        if len(perturbed_explain_vector.shape) == 1:\n",
    "            perturbed_explain_vector = perturbed_explain_vector.unsqueeze(0)\n",
    "        if len(original_explain_vector.shape) == 1:\n",
    "            original_explain_vector = original_explain_vector.unsqueeze(0)\n",
    "        # Compute cosine similarity between the original and perturbed explainability vectors\n",
    "        similarity = torch.nn.functional.cosine_similarity(original_explain_vector, perturbed_explain_vector).numpy()\n",
    "        \n",
    "        \n",
    "        explain_diff_magnitudes.append(similarity)\n",
    "\n",
    "    # Compute the average magnitude of differences as the robustness score\n",
    "    robustness_score = np.mean(explain_diff_magnitudes)\n",
    "\n",
    "    return robustness_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_robustness(experiment_path, seeds, perturbation_scale=0.01, num_perturbations=50, n_samples= 200):\n",
    "    \"\"\"\n",
    "    Compute the mean robustness score for a set of experiments.\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_path: str\n",
    "        The path to the directory containing the experiment results.\n",
    "    - seeds: list\n",
    "        A list of seeds for which to compute the mean robustness score.\n",
    "    - perturbation_scale: float\n",
    "        The standard deviation of Gaussian noise added to the input for perturbations.\n",
    "    - num_perturbations: int\n",
    "        The number of perturbed instances to generate.\n",
    "\n",
    "    Returns:\n",
    "    - mean_robustness: float\n",
    "        The mean robustness score across all seeds.\n",
    "    \"\"\"\n",
    "    robustness_scores = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        print('Processing seed:', seed)\n",
    "        # Load the experiment results\n",
    "        seed_experiment_path = Path(f\"{experiment_path}_seed_{seed}\")\n",
    "        seed_experiment_config_path = Path(f\"{seed_experiment_path}/experiment_config.yaml\")\n",
    "        model_path = f\"{seed_experiment_path}/model.pth\"\n",
    "            \n",
    "        with initialize(config_path=str(seed_experiment_path), version_base=None):\n",
    "            cfg = compose(config_name=seed_experiment_config_path.name)\n",
    "        cfg.dataset.dataset_path = \"../\" + cfg.dataset.dataset_path\n",
    "        dataset = get_dataset(cfg)\n",
    "        X = dataset['X_test']\n",
    "        y = dataset['y_test']\n",
    "        explanation = dataset['explanation_test']\n",
    "\n",
    "        # keep only data with label != 0\n",
    "        X = X[y != 0]\n",
    "        explanation = explanation[y != 0]\n",
    "        y = y[y != 0]\n",
    "\n",
    "        # Select 200 random instances from the dataset\n",
    "        random_indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "        instances = X[random_indices]\n",
    "        explanations = explanation[random_indices]\n",
    "        labels = y[random_indices]\n",
    "        model = select_model(cfg.model, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.load_model(model_path, X)\n",
    "        seed_shap_robustness_scores = []\n",
    "        seed_ours_robustness_scores = []\n",
    "        seed_gradient_robustness_scores = []\n",
    "        explainer = ShapExplainer(model, X)\n",
    "        for instance in tqdm(instances):\n",
    "            shap_robustness = evaluate_explainability_robustness(model, instance, explainer.explain_instance, perturbation_scale=perturbation_scale, num_perturbations=num_perturbations)\n",
    "            ours_robustness = evaluate_explainability_robustness(model, instance, model.instance_explanation, perturbation_scale=perturbation_scale, num_perturbations=num_perturbations)\n",
    "            gradient_robustness = evaluate_explainability_robustness(model, instance, model.gradient_explanation, perturbation_scale=perturbation_scale, num_perturbations=num_perturbations)\n",
    "            \n",
    "            seed_shap_robustness_scores.append(shap_robustness)\n",
    "            seed_ours_robustness_scores.append(ours_robustness)\n",
    "            seed_gradient_robustness_scores.append(gradient_robustness)\n",
    "\n",
    "        shap_robustness_scores = np.array(seed_shap_robustness_scores)\n",
    "        ours_robustness_scores = np.array(seed_ours_robustness_scores)\n",
    "        gradient_robustness_scores = np.array(seed_gradient_robustness_scores)\n",
    "\n",
    "        shap_robustness = np.mean(shap_robustness_scores)\n",
    "        ours_robustness = np.mean(ours_robustness_scores)\n",
    "        gradient_robustness = np.mean(gradient_robustness_scores)\n",
    "    \n",
    "        robustness_scores.append({\n",
    "            \"seed\": seed,\n",
    "            \"shap\": shap_robustness,\n",
    "            \"ours\": ours_robustness,\n",
    "            \"gradient\": gradient_robustness\n",
    "        })\n",
    "    robustness_scores = pd.DataFrame(robustness_scores)\n",
    "    return robustness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed: 0\n",
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a0f05434164a98afe66ba048ee9f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:327: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x[:, i]),\n",
      "/tmp/ipykernel_2142484/2033525961.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_explain_vector = torch.tensor(explain_func(instance))\n",
      "/tmp/ipykernel_2142484/2033525961.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  perturbed_explain_vector = torch.tensor(explain_func(perturbed_instance))\n",
      "/home/elouan/code/code_repo/src/models/dte.py:327: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x[:, i]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed: 1\n",
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6170dc5590614ea19639ebed08005d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:327: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x[:, i]),\n",
      "/tmp/ipykernel_2142484/2033525961.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_explain_vector = torch.tensor(explain_func(instance))\n",
      "/tmp/ipykernel_2142484/2033525961.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  perturbed_explain_vector = torch.tensor(explain_func(perturbed_instance))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed: 2\n",
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ed3a4a13cd4772bcbe947eedf75c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:327: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x[:, i]),\n",
      "/tmp/ipykernel_2142484/2033525961.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_explain_vector = torch.tensor(explain_func(instance))\n",
      "/tmp/ipykernel_2142484/2033525961.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  perturbed_explain_vector = torch.tensor(explain_func(perturbed_instance))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed: 3\n",
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94cbd42eef545a99d8c9ac2bde1dae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:327: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x[:, i]),\n",
      "/tmp/ipykernel_2142484/2033525961.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_explain_vector = torch.tensor(explain_func(instance))\n",
      "/tmp/ipykernel_2142484/2033525961.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  perturbed_explain_vector = torch.tensor(explain_func(perturbed_instance))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed: 4\n",
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a4e142d615450fa9546daa33f2867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:327: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x[:, i]),\n",
      "/tmp/ipykernel_2142484/2033525961.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_explain_vector = torch.tensor(explain_func(instance))\n",
      "/tmp/ipykernel_2142484/2033525961.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  perturbed_explain_vector = torch.tensor(explain_func(perturbed_instance))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>shap</th>\n",
       "      <th>ours</th>\n",
       "      <th>gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.978009</td>\n",
       "      <td>0.998978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.977579</td>\n",
       "      <td>0.998953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.977434</td>\n",
       "      <td>0.999463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.975731</td>\n",
       "      <td>0.999455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.975502</td>\n",
       "      <td>0.999015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed    shap      ours  gradient\n",
       "0     0  0.9920  0.978009  0.998978\n",
       "1     1  0.9928  0.977579  0.998953\n",
       "2     2  0.9928  0.977434  0.999463\n",
       "3     3  0.9920  0.975731  0.999455\n",
       "4     4  0.9992  0.975502  0.999015"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mean_robustness(experiment_path= \"../results/all_db_all_training/DTEC_DSIL_deterministic_exponential_s0_T400_bins7/A_synthetic_f10_s5000_c4_r0.0166_0.0166_0.0166\", seeds=[0,1,2,3,4], perturbation_scale=0.01, num_perturbations=5, n_samples= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dcg_score_matrix_p(importance_scores, relevance_matrix, p):\n",
    "    \"\"\"\n",
    "    Compute the DCG scores at a given cutoff rank p.\n",
    "    \"\"\"\n",
    "    importance_scores = np.array(importance_scores)\n",
    "    relevance_matrix = np.array(relevance_matrix)\n",
    "    importance_scores = importance_scores.squeeze()\n",
    "    relevance_matrix = relevance_matrix.squeeze()\n",
    "    assert (\n",
    "        importance_scores.shape == relevance_matrix.shape\n",
    "    ), \"importance_scores and relevance_matrix must have the same shape\"\n",
    "\n",
    "    # Sort relevance based on importance scores\n",
    "    if len(importance_scores.shape) == 1:\n",
    "        importance_scores = importance_scores.reshape(1, -1)\n",
    "        relevance_matrix = relevance_matrix.reshape(1, -1)\n",
    "\n",
    "    sorted_indices = np.argsort(importance_scores, axis=1)[:, ::-1]\n",
    "    sorted_relevance = np.take_along_axis(\n",
    "        relevance_matrix, sorted_indices, axis=1\n",
    "    )\n",
    "\n",
    "    # Consider only the top p items\n",
    "    sorted_relevance_p = sorted_relevance[:, :p]\n",
    "    ranks = np.arange(1, p + 1)  # Ranks from 1 to p\n",
    "\n",
    "    # Compute DCG scores\n",
    "    dcg_scores = np.sum(sorted_relevance_p / np.log2(ranks + 1), axis=1)\n",
    "\n",
    "    return dcg_scores\n",
    "\n",
    "\n",
    "def idcg_score_matrix_p(relevance_matrix, p):\n",
    "    \"\"\"\n",
    "    Compute the IDCG scores at a given cutoff rank p.\n",
    "    \"\"\"\n",
    "    if len(relevance_matrix.shape) == 1:\n",
    "        relevance_matrix = relevance_matrix.reshape(1, -1)\n",
    "    relevance_matrix = np.array(relevance_matrix)\n",
    "    sorted_relevance = np.sort(relevance_matrix, axis=1)[:, ::-1]\n",
    "\n",
    "    # Consider only the top p items\n",
    "    sorted_relevance_p = sorted_relevance[:, :p]\n",
    "    ranks = np.arange(1, p + 1)  # Ranks from 1 to p\n",
    "\n",
    "    # Compute IDCG scores\n",
    "    idcg_scores = np.sum(sorted_relevance_p / np.log2(ranks + 1), axis=1)\n",
    "\n",
    "    return idcg_scores\n",
    "\n",
    "\n",
    "def nDCG_(importance_scores, relevance_matrix, p):\n",
    "    \"\"\"\n",
    "    Compute the nDCG scores at a given cutoff rank p.\n",
    "    \"\"\"\n",
    "    dcg_scores_p = dcg_score_matrix_p(importance_scores, relevance_matrix, p)\n",
    "    idcg_scores_p = idcg_score_matrix_p(relevance_matrix, p)\n",
    "\n",
    "    # Compute normalized DCG\n",
    "    ndcg_scores_p = np.zeros_like(dcg_scores_p)\n",
    "    for i in range(len(dcg_scores_p)):\n",
    "        if idcg_scores_p[i] == 0:\n",
    "            ndcg_scores_p[i] = 0\n",
    "        else:\n",
    "            ndcg_scores_p[i] = dcg_scores_p[i] / idcg_scores_p[i]\n",
    "\n",
    "    return ndcg_scores_p\n",
    "\n",
    "\n",
    "def nDCG_p(importance_scores, relevance_matrix, k= 'auto'):\n",
    "    nDCG_scores = []\n",
    "    if len(importance_scores.shape) == 1:\n",
    "        importance_scores = importance_scores.reshape(1, -1)\n",
    "    if len(relevance_matrix.shape) == 1:\n",
    "        relevance_matrix = relevance_matrix.reshape(1, -1)\n",
    "    for i in range(importance_scores.shape[0]):\n",
    "        if k == \"auto\":\n",
    "            k_ = int(np.sum(relevance_matrix[i]))\n",
    "        else:\n",
    "            k_ = k\n",
    "        if k_ == 0 or int(np.sum(relevance_matrix[i])) == 0:\n",
    "            continue\n",
    "        nDCG_scores.append(nDCG_(importance_scores[i], relevance_matrix[i], p=k_))\n",
    "    return np.array(nDCG_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_accuracy(ground_truth, explanation, k=\"auto\"):\n",
    "    if explanation.shape != ground_truth.shape:\n",
    "        raise ValueError(\n",
    "            \"The explanation and ground truth must have the same shape.\"\n",
    "        )\n",
    "    if len(explanation.shape) == 1:\n",
    "        explanation = explanation.reshape(1, -1)\n",
    "    if len(ground_truth.shape) == 1:\n",
    "        ground_truth = ground_truth.reshape(1, -1)\n",
    "    if type(explanation) is torch.Tensor:\n",
    "        explanation = explanation.cpu().detach().numpy()\n",
    "    if type(ground_truth) is torch.Tensor:\n",
    "        ground_truth = ground_truth.cpu().detach().numpy()\n",
    "    accuracy = []\n",
    "    for row in range(ground_truth.shape[0]):\n",
    "        if k == \"auto\":\n",
    "            k_ = int(np.sum(ground_truth[row]))\n",
    "        else:\n",
    "            k_ = k\n",
    "        if k_ == 0 or int(np.sum(ground_truth[row])) == 0:\n",
    "            continue\n",
    "        sorted_indices = np.argsort(explanation[row])[::-1]\n",
    "        instance_explanation = np.zeros_like(explanation[row])\n",
    "        instance_explanation[sorted_indices[:k_]] = 1\n",
    "\n",
    "        instance_accuracy = (\n",
    "            np.sum(ground_truth[row] * instance_explanation) / k_\n",
    "        )\n",
    "        accuracy.append(instance_accuracy)\n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_instance_set(model, instances, ground_truths):\n",
    "    \"\"\"\n",
    "    Compute the explainability vectors for a set of instances.\n",
    "\n",
    "    Parameters:\n",
    "    - model: torch.nn.Module\n",
    "        The PyTorch model to be evaluated.\n",
    "    - instances: torch.Tensor\n",
    "        The input instances for which the explainability vectors are computed (2D tensor).\n",
    "    - explain_func: function\n",
    "        A function that takes `model` and `instance` as inputs and returns an explainability vector.\n",
    "\n",
    "    Returns:\n",
    "    - explain_vectors: torch.Tensor\n",
    "        The explainability vectors for the input instances.\n",
    "    \"\"\"\n",
    "    model.model.eval()  # Ensure the model is in evaluation mode\n",
    "    nDCGs={\"shap\": [], \"max_diffusion\": [], \"mean_diffusion\": [], \"gradient\": []}\n",
    "    accuracy={\"shap\": [], \"max_diffusion\": [], \"mean_diffusion\": [], \"gradient\": []}\n",
    "    shap_explainer = ShapExplainer(model, instances)\n",
    "    shap_explanation = shap_explainer.explain_instance(instances).squeeze()\n",
    "    max_diffusion_explanation = model.instance_explanation(instances, step=10, agg=\"max\")\n",
    "    mean_diffusion_explanation = model.instance_explanation(instances, step=10, agg=\"mean\")\n",
    "    gradient_explanation = model.gradient_explanation(instances)\n",
    "\n",
    "    # Compute nDCG and accuracy for each method\n",
    "    for i in range(ground_truths.shape[0]):\n",
    "        shap_ndcg = nDCG_p(shap_explanation[i,:], ground_truths[i,:])\n",
    "        max_diffusion_ndcg = nDCG_p(max_diffusion_explanation[i,:], ground_truths[i,:])\n",
    "        mean_diffusion_ndcg = nDCG_p(mean_diffusion_explanation[i,:], ground_truths[i,:])\n",
    "        gradient_ndcg = nDCG_p(gradient_explanation[i,:], ground_truths[i,:])\n",
    "        shap_accuracy = explanation_accuracy(ground_truths[i,:], shap_explanation[i,:])\n",
    "        max_diffusion_accuracy = explanation_accuracy(ground_truths[i,:], max_diffusion_explanation[i,:])\n",
    "        mean_diffusion_accuracy = explanation_accuracy(ground_truths[i,:], mean_diffusion_explanation[i,:])\n",
    "        gradient_accuracy = explanation_accuracy(ground_truths[i,:], gradient_explanation[i,:])\n",
    "\n",
    "        nDCGs[\"shap\"].append(shap_ndcg[0][0])\n",
    "        nDCGs[\"max_diffusion\"].append(max_diffusion_ndcg[0][0])\n",
    "        nDCGs[\"mean_diffusion\"].append(mean_diffusion_ndcg[0][0])\n",
    "        nDCGs[\"gradient\"].append(gradient_ndcg[0][0])\n",
    "        accuracy[\"shap\"].append(shap_accuracy)\n",
    "        accuracy[\"max_diffusion\"].append(max_diffusion_accuracy)\n",
    "        accuracy[\"mean_diffusion\"].append(mean_diffusion_accuracy)\n",
    "        accuracy[\"gradient\"].append(gradient_accuracy)\n",
    "\n",
    "    return nDCGs, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsil_exp_path = \"../results/all_db_all_training/DTEC_DSIL_deterministic_0.5_s0_T400_bins7/A_synthetic_f10_s5000_c4_r0.0166_0.0166_0.0166_seed_3\"\n",
    "unsup_exp_path = \"../results/all_db_all_training/DTEC_unsupervised_None_s0_T400_bins7/A_synthetic_f10_s5000_c4_r0.0166_0.0166_0.0166_seed_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_dataset_from_path(experiment_path, n_samples=200):\n",
    "    cfg_experiment_path = Path(f\"{experiment_path}/experiment_config.yaml\")\n",
    "    model_path = f\"{experiment_path}/model.pth\"\n",
    "        \n",
    "    with initialize(config_path=str(experiment_path), version_base=None):\n",
    "        cfg = compose(config_name=cfg_experiment_path.name)\n",
    "    cfg.dataset.dataset_path = \"../\" + cfg.dataset.dataset_path\n",
    "    dataset = get_dataset(cfg)\n",
    "    X = dataset['X_test']\n",
    "    y = dataset['y_test']\n",
    "    explanation = dataset['explanation_test']\n",
    "\n",
    "    # keep only data with label != 0\n",
    "    X = X[y != 0]\n",
    "    explanation = explanation[y != 0]\n",
    "    y = y[y != 0]\n",
    "\n",
    "    # Select 200 random instances from the dataset\n",
    "    random_indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "    instances = X[random_indices]\n",
    "    explanations = explanation[random_indices]\n",
    "    labels = y[random_indices]\n",
    "    model = select_model(cfg.model, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.load_model(model_path, X)\n",
    "    return model, instances, explanations, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samples': 5000, 'Features': 10, 'Anomalies': 249, 'Anomalies Ratio(%)': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouan/code/code_repo/src/models/dte.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "dsil_model, dsil_instances, dsil_explanations, dsil_labels = load_model_and_dataset_from_path(dsil_exp_path)\n",
    "unsup_model, unsup_instances, unsup_explanations, unsup_labels = load_model_and_dataset_from_path(unsup_exp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsil_explanability = explain_instance_set(dsil_model, dsil_instances, dsil_explanations)\n",
    "unsup_explanability = explain_instance_set(unsup_model, dsil_instances, dsil_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsil_ndcg, dsil_accuracy = dsil_explanability\n",
    "unsup_ndcg, unsup_accuracy = unsup_explanability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean for every key\n",
    "dsil_accuracy_mean = {key: np.mean(value) for key, value in dsil_accuracy.items()}\n",
    "unsup_accuracy_mean = {key: np.mean(value) for key, value in unsup_accuracy.items()}\n",
    "dsil_ndcg_mean = {key: np.mean(value) for key, value in dsil_ndcg.items()}\n",
    "unsup_ndcg_mean = {key: np.mean(value) for key, value in unsup_ndcg.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'shap': 0.665,\n",
       "  'max_diffusion': 0.5833333333333333,\n",
       "  'mean_diffusion': 0.6575,\n",
       "  'gradient': 0.6},\n",
       " {'shap': 0.64,\n",
       "  'max_diffusion': 0.5883333333333334,\n",
       "  'mean_diffusion': 0.6266666666666666,\n",
       "  'gradient': 0.6025},\n",
       " {'shap': 0.6891769500834437,\n",
       "  'max_diffusion': 0.6108671933466101,\n",
       "  'mean_diffusion': 0.6981945384400114,\n",
       "  'gradient': 0.6281440035760606},\n",
       " {'shap': 0.6763007900199153,\n",
       "  'max_diffusion': 0.6100011463888363,\n",
       "  'mean_diffusion': 0.6599049766287269,\n",
       "  'gradient': 0.6300504719814615})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsil_accuracy_mean, unsup_accuracy_mean, dsil_ndcg_mean, unsup_ndcg_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
